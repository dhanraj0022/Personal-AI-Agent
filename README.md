ğŸ“˜ Personal AI Agent â€” Local LLM + GitHub Automation
ğŸš€ Overview

This project is a local-first personal AI agent system designed to:

Run fully offline using Ollama

Use task-specific LLM models

Generate structured Markdown (.md) knowledge files

Maintain clean GitHub version control

Support future RAG (Retrieval-Augmented Generation) workflows

The system is built with modular agent architecture, making it extensible for learning, DSA tracking, AI study notes, and automated documentation.

ğŸ§  Core Objectives

âœ… Local LLM execution (no API costs)

âœ… Clear separation of responsibilities (router, writer, orchestrator)

âœ… Git-safe automation (no venv or secrets committed)

âœ… Markdown-first knowledge storage

âœ… Designed for long-term learning tracking

ğŸ“ Project Structure
Personal-AI-Agent/
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ orchestrator.py     # Main controller (task flow)
â”‚   â”œâ”€â”€ llm.py              # Ollama LLM interface
â”‚   â”œâ”€â”€ writer.py           # Markdown generation
â”‚   â”œâ”€â”€ router.py           # Task routing (future use)
â”‚   â”œâ”€â”€ github.py           # Git automation (optional)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ notes/              # Generated .md files
â”‚
â”œâ”€â”€ config.yaml             # Model + system configuration
â”œâ”€â”€ main.py                 # Application entry point
â”‚
â”œâ”€â”€ commit.bat              # One-command Git automation
â”œâ”€â”€ .gitignore              # Prevents venv, cache, secrets
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â””â”€â”€ venv/                   # Local only (never pushed)

âš™ï¸ Technologies Used

Python 3.11

Ollama (local LLM runtime)

Phi-3 Mini (lightweight low-memory model)

Nomic Embed Text (for future RAG)

Git + GitHub

Markdown-based knowledge storage

ğŸ§© Installed Ollama Models
Purpose	Model
General reasoning	phi3:mini
Code generation	deepseek-coder:6.7b
Embeddings	nomic-embed-text

âš ï¸ Large models like LLaMA/Gemma require higher RAM and may not run on low-memory systems.

ğŸ›  Setup Steps (Completed)
1ï¸âƒ£ Python Environment

Installed Python 3.11.x

Created virtual environment:

python -m venv venv
venv\Scripts\activate

2ï¸âƒ£ Dependency Installation
pip install -r requirements.txt


Key libraries:

ollama

pyyaml

gitpython

3ï¸âƒ£ Ollama Setup

Install Ollama and pull required models:

ollama pull phi3:mini
ollama pull nomic-embed-text


Start Ollama server:

ollama serve


Ollama runs locally on:

http://localhost:11434

4ï¸âƒ£ Configuration File (config.yaml)
model:
  default: phi3:mini

github:
  enabled: false


GitHub automation can be enabled later.

5ï¸âƒ£ Running the Application
python main.py


This will:

Call the local LLM

Generate markdown content

Save files into structured folders

Avoid pushing venv or system files

ğŸ” Git Automation (Optional)

A batch script simplifies Git usage:

commit.bat
@echo off
setlocal EnableDelayedExpansion

if "%~1"=="" (
    set "msg=AI update"
) else (
    set "msg=%~1"
)

git add .
git commit -m "%msg%"
git push


Usage:

.\commit.bat "Add DSA sliding window notes"


âœ” Clean
âœ” Safe
âœ” Repeatable

ğŸ”’ Git Safety

The following are ignored permanently:

venv/
__pycache__/
.env
*.pyc


This ensures:

No environment files pushed

No secrets leaked

Clean repository history

ğŸ§  Design Philosophy
Separation of Concerns
Component	Responsibility
orchestrator	Workflow control
llm	Model interaction
writer	File creation
router	Task-based routing
github	Optional push automation

This mirrors production-grade backend design.

ğŸ”® Planned Enhancements

 RAG using embeddings

 Date-based progress retrieval

 Multi-model routing (DSA vs AI vs summaries)

 Google Drive integration

 Auto-generated commit messages

 Daily learning tracker

 Semantic search over markdown files

ğŸ§‘â€ğŸ’» Author

Dhanraj Singh
Built as a long-term learning companion and AI experimentation platform.

âœ… Status

ğŸŸ¢ Working
ğŸŸ¢ Local LLM operational
ğŸŸ¢ GitHub integrated
ğŸŸ¢ Ready for expansion
